_target_: self_attention_cv.UnetTr.UNETR

img_shape: ${data.shape}
input_dim: ${data.num_channels}
output_dim: ${data.num_classes}

# transformer params
patch_size: 16
# = 4..6..8..12
num_heads: 6
# embed_dim = num heads * 64
embed_dim: 384
# dim_linear_block = embed_dim * (1..4)
dim_linear_block: 1536
dropout: 0.1

# conv params
ext_layers: [3, 6, 9, 12]
norm: instance
base_filters: 16
